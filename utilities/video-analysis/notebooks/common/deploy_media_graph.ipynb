{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deploy Media Graph\n",
    "\n",
    "In this section, we will deploy media graphs onto our IoT Edge device to trigger our modules to perform certain actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy / Manage Media Graph on LVA Edge Module\n",
    "At this stage of the sample, we should have all required modules deployed to the Edge device, up and running.  \n",
    "\n",
    "Now we will deploy media graphs onto the \"lvaEdge\" module. Here, \"lvaEdge\" is the name that we assigned to the LVA module inside the module deployment template json file from the [previous sample](08_deploy_iotedge_modules.ipynb). Media graph is also a Json file that defines a media flow pipeline from media sources to the target sinks and any analytics processes in-between. The media graph file consists of following modules:  \n",
    "\n",
    "```\n",
    "{\n",
    "    \"@apiVersion\": \"1.0\",\n",
    "\n",
    "    \"name\": \"SampleMediaGraphOrganization\",\n",
    "\n",
    "    \"properties\":{\n",
    "\n",
    "        \"parameters\": ...\n",
    "\n",
    "        \"sources\": ...\n",
    "\n",
    "        \"processes\": ...\n",
    "\n",
    "        \"sinks\": ...\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "In the media graph Json file above, the \"parameters\" section is the most critical part of the media graph. The \"parameters\" section defines all required parameters to run the media graph. In this section, we will define the addresses of the media sources, their access credentials, and the parameters related to the process modules, such as fps rate and sensitivity of motion detection. Each media graph may have a different media flow, i.e., one may have a motion detection processor while another may not. You may modify this media graph according to your needs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Media Graph\n",
    "In this sample, we provide a sample media graph file [template.json](../../../../MediaGraph/topologies/motion-with-httpExtension/topology.json) under the MediaGraph/topologies/motion-with-httpExtension folder.  The media graph in this file ingests a video stream from a single IP camera, runs motion detector processor on the stream, and sends the stream to one of two targets if there is motion.  \n",
    "\n",
    "In the sample media graph topology, we define two \"sink\" nodes:  \n",
    "* Sink 1 - sends the stream chunks (where motion detected) into Azure Media Services\n",
    "* Sink 2 - sends the inference result (Json payload) to IoT Hub\n",
    "\n",
    "If you wish to send your inference results to another location or to alter the settings of the inference recordings, you can change the sink settings of the media graph topology in [template.json](../../../../MediaGraph/topologies/motion-with-httpExtension/topology.json) or by setting their values as we show below. \n",
    "\n",
    "The settings are as follows:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"activationEvaluationWindow\": \"PT1S\",    // Period of time for evaluating event inputs\n",
    "  \"activationSignalOffset\": \"PT0S\",        // Signal offset once activated (can be negative)\n",
    "  \"minimumActivationTime\": \"PT30S\",        // Minimum period of activation in the absence of subsequent events\n",
    "  \"maximumActivationTime\": \"PT30S\",        // Minimum period of activation in the presence of subsequent events\n",
    "  \"inputs\": []\n",
    "}\n",
    "```\n",
    "\n",
    "For more details, [read more about LVA media graphs](https://docs.microsoft.com/en-us/azure/media-services/live-video-analytics-edge/media-graph-concept). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Parameters in Media Graph\n",
    "There are two ways to set parameters in the media graph:  \n",
    "\n",
    "1. Update the default values of the parameters in \"template.json\", which is **not** the prefered method. \n",
    "2. Note the parameter names and data types in \"template.json\", and set their values in the deployment command that we will show in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Media Graph with Custom Parameters\n",
    "Below, we will explain the following operations:\n",
    "\n",
    "1. Setting (deploying) Media Graph Topology on the IoT Edge Device's lvaEdge module\n",
    "2. Creating a Media Topolgy Instance from the one set in step 1\n",
    "3. Activate the Topology Instance that set in step 2\n",
    "\n",
    "We will also show how to\n",
    "* List and delete the already set Graph Topologies on the Device\n",
    "* List and delete the already set Graph Instances on the Device\n",
    "* Activate / deactivate the Graph Instances (in a later section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Prerequisites\n",
    "We will use a simple Python script to deploy our media graph Json file into the \"lvaEdge\" module. Our process entails sending a file into the IoT Edge device over the Internet through a IoT Edge Hub service. To do so, we need to install following Python packages. These packages were developed by Microsoft and help with interacting with IoT Hub Services.\n",
    "\n",
    "!Important: As mentioned in the first section of this tutorial, you must use the right ```pip``` command (```pip``` or ```pip3```) depending on your Python installation. This sample is tested with Python version 3.6 and so we use the ```pip3``` command to install the packages into our Python3 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install azure-iot-device\n",
    "!pip3 install azure-iot-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import A Helper Python Class to Deploy Media Graphs\n",
    "The following code snippet will import a custom Python class to help us deploy media edge graphs. After the import, we will instantiate a graph manager object with IoT Hub, IoT Edge Device, and Graph API version details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../shared/graph_manager')\n",
    "from graph_manager import GraphManager\n",
    "from env_variables import *\n",
    "\n",
    "moduleId = \"lvaEdge\" # Must be same as the name that we assigned to LVA module in the deployment manifest file\n",
    "operationsApiVersion = \"1.0\"  # Must be same as the version number in the deployment manifest file\n",
    "\n",
    "graphManager = GraphManager(iotHubConnString, iotDeviceId, moduleId, operationsApiVersion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Existing Graph Topologies and Instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List topologies\n",
    "response = graphManager.GenericCall(\"GraphTopologyList\", {})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List instances\n",
    "response = graphManager.GenericCall(\"GraphInstanceList\", {})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Topology\n",
    "The following code snippet will deploy the \"template.json\" file into the lvaEdge module running on our IoT Edge device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can define a topologyFile or a topologyUrl that you want to deploy into the module. Here we point to our sample Media Graph Topology File.\n",
    "operationParams = {\n",
    "                    \"topologyFile\": \"../../../../MediaGraph/topologies/motion-with-httpExtension/topology.json\"\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Graph Topology\n",
    "response = graphManager.GraphTopologySet(operationParams)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Topology Instance\n",
    "\n",
    "The following code snippet will set the values of the parameters mentioned in \"template.json\" and will create a Topology Instance. If you modify the topology or add new parameters, you should update the parameter list below accordingly.  \n",
    "\n",
    ">[!IMPORTANT]  \n",
    ">- Be sure that the value of \"topologyName\" parameter below and the same parameter in the \"template.json\" file are the same.  \n",
    ">- Since we don't have a physical IP camera set for this sample, we use a virtual IP camera simulator. In the previous section, when we deployed the module deployment manifest, we already deployed a simulator module which plays \"lots_284.mkv\" video file as if played from an IP camera. Thus, in the parameter list below, the parameter \"rtspUrl\" points to the URL address of this IoT Module (rtsp://rtspsim:554) with the full path of the video file that we want to play. You can replace this parameter's value with full RTSP address of your phyical IP camera or with another video clip in the /lvafolders/input folder of your IoT Edge device.  \n",
    ">- rtspUsername and rtspPassword are dummy values for our simulator because they do not require authentication. However, if your source stream (i.e., your phyical IP Camera) requires authentication, then put the appropriate values for these parameters.  \n",
    ">- The value of the \"motionSensitivity\" parameter can be one of: {low, medium, high}. As the name implies, it sets the sensitivity of the motion detection processor.\n",
    ">- The value of the \"grpcAIServerAddress\" parameter points to the address of the inference server. The name of the module that we developed in this sample and deployed in our module deployment manifest was set to \"lvaExtension\", which was listening to an inference request on \"/score\" endpoint through port 44001. Here, we set the exact address of the scoring endpoint.\n",
    ">- The \"hubSinkOutputName\" parameter sets the IoT Hub channel name which ingests inference results into IoT Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaGraphTopologyParameters = {\n",
    "          \"name\": \"Sample-Graph-1\",\n",
    "          \"properties\": {\n",
    "            \"topologyName\": \"EVROnMotionPlusHttpExtension\",\n",
    "            \"description\": \"Sample graph description\",\n",
    "            \"parameters\": [\n",
    "              {\n",
    "                \"name\": \"rtspUserName\",\n",
    "                \"value\": \"username\"\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"rtspPassword\",\n",
    "                \"value\": \"password\"\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"rtspUrl\",\n",
    "                \"value\": \"rtsp://rtspsim:554/media/lots_284.mkv\"\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"motionSensitivity\",\n",
    "                \"value\": \"medium\"\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"httpAIServerAddress\",\n",
    "                \"value\": \"http://lvaExtension:5001/score\"\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"hubSinkOutputName\",\n",
    "                \"value\": \"inferences\"\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"imageEncoding\",\n",
    "                \"value\": \"jpeg\"\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"imageScaleMode\",\n",
    "                \"value\": \"pad\"\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting the parameters above (as Python dictionary data structure), we can now set an instance of the previously deployed topology on the Edge device with the custom parameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set topology instance\n",
    "response = graphManager.GenericCall(\"GraphInstanceSet\", mediaGraphTopologyParameters)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate Topology Instance\n",
    "Next, we activate the Topology Instance that we set in the previous node.\n",
    "\n",
    ">[!IMPORTANT]  \n",
    ">Be sure to set the name parameter below to the exact topology instance name that we used in the previous node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate topology instance\n",
    "operationParams = {\n",
    "                    \"name\": \"Sample-Graph-1\"\n",
    "                    }\n",
    "\n",
    "response = graphManager.GenericCall(\"GraphInstanceActivate\", operationParams)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "If all the code cells above have successfully finished running, return to the Readme page to continue.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
