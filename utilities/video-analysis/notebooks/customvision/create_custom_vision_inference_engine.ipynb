{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": [
        "# Create a TensorFlow Inference Engine\n",
        "In this section, we will create an inference engine wrapper, a class that will get image data as input, analyze it, and return the analysis result."
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Get Global Variables\n",
        "\n",
        "First, read the previously stored variables. We need the name of the directory that will be used to store our ML solution files. If this directory does not exist, we will create a directory with a specified directory name."
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('../common')\n",
        "from env_variables import *\n",
        "\n",
        "import os\n",
        "if not os.path.exists(lvaExtensionPath):\n",
        "    os.mkdir(lvaExtensionPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Create Inference Engine Wrapper\n",
        "Next, we will create a class that with different properties and methods to help scoring and analyzing data from an image.\n",
        "\n",
        "> <span style=\"color:red; font-weight: bold\"> [!IMPORTANT] </span>\n",
        "> Specific to this sample, we are using the TensorFlow model you exported from Custom Vision. As you can see from the code below,  \n",
        "> * The YOLOv3 model accepts only raw image bytes with 416 by 416 in size.  \n",
        "> * Because we expect the `score` method to receive raw bytes of this size (416x416), we have statically coded the image size into our code. If the image is not 416x416 float32, then the code will crash.\n",
        "> * Why do we statically code the image size? LVA sends video frames to the `score` endpoint. In fact, LVA can send any image size and format. Since LVA can send images with 416x416 size, we do not need to spend additional compute cycles for re-sizing an image."
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "%%writefile $lvaExtensionPath/score.py\n",
        "import threading\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import linecache\n",
        "import sys\n",
        "import math\n",
        "from object_detection import ObjectDetection\n",
        "\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "\n",
        "def PrintGetExceptionDetails():\n",
        "    exType, exValue, exTraceback = sys.exc_info()\n",
        "\n",
        "    tbFrame = exTraceback.tb_frame\n",
        "    lineNo = exTraceback.tb_lineno\n",
        "    fileName = tbFrame.f_code.co_filename\n",
        "\n",
        "    linecache.checkcache(fileName)\n",
        "    line = linecache.getline(fileName, lineNo, tbFrame.f_globals)\n",
        "\n",
        "    exMessage = '[LVAX] Exception:\\n\\tFile name: {0}\\n\\tLine number: {1}\\n\\tLine: {2}\\n\\tValue: {3}'.format(fileName, lineNo, line.strip(), exValue)\n",
        "\n",
        "    logging.info(exMessage)\n",
        "\n",
        "class TFObjectDetection(ObjectDetection):\n",
        "    \"\"\"Object Detection class for TensorFlow\"\"\"\n",
        "\n",
        "    def __init__(self, graph_def, labels, prob_threshold, max_detections):\n",
        "        super(TFObjectDetection, self).__init__(labels, prob_threshold, max_detections)\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        with self.graph.as_default():\n",
        "            input_data = tf.compat.v1.placeholder(tf.float32, [1, None, None, 3], name='Placeholder')\n",
        "            tf.import_graph_def(graph_def, input_map={\"Placeholder:0\": input_data}, name=\"\")\n",
        "\n",
        "    def predict(self, preprocessed_image):\n",
        "        inputs = np.array(preprocessed_image, dtype=np.float)[:, :, (2, 1, 0)]  # RGB -> BGR\n",
        "\n",
        "        with tf.compat.v1.Session(graph=self.graph) as sess:\n",
        "            output_tensor = sess.graph.get_tensor_by_name('model_outputs:0')\n",
        "            outputs = sess.run(output_tensor, {'Placeholder:0': inputs[np.newaxis, ...]})\n",
        "            return outputs[0]\n",
        "\n",
        "class MLModel:\n",
        "    \n",
        "    def __init__(self):\n",
        "        try:\n",
        "            self._modelFileName = 'model.pb'\n",
        "            self._labelFileName = 'labels.txt'\n",
        "            self._lock = threading.Lock()\n",
        "            self.prob_threshold = 0.1\n",
        "            self.max_detections = 20\n",
        "\n",
        "            graph_def = tf.compat.v1.GraphDef()\n",
        "            with tf.io.gfile.GFile(self._modelFileName, 'rb') as f:\n",
        "                graph_def.ParseFromString(f.read())\n",
        "\n",
        "            # Load labels\n",
        "            with open(self._labelFileName, 'r') as f:\n",
        "                labels = [l.strip() for l in f.readlines()]\n",
        "\n",
        "            self.od_model = TFObjectDetection(graph_def, labels, self.prob_threshold, self.max_detections)\n",
        "\n",
        "        except:\n",
        "            PrintGetExceptionDetails()\n",
        "\n",
        " \n",
        "    def Score(self, pilImage):\n",
        "        try:\n",
        "            with self._lock:\n",
        "                predictions = self.od_model.predict_image(pilImage)\n",
        "\n",
        "                return predictions\n",
        "\n",
        "        except:\n",
        "            PrintGetExceptionDetails()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `score` method of the inference engine class above will return a dictionary of inferences in the following form:\n",
        "\n",
        "```\n",
        "{\n",
        "  \"type\": \"entity\",\n",
        "  \"entity\": {\n",
        "    \"tag\": {\n",
        "      \"value\": \"delivery truck\",\n",
        "      \"confidence\": \"0.9596136\"\n",
        "    },\n",
        "    \"box\": {\n",
        "      \"l\": \"0.69242793\",\n",
        "      \"t\": \"0.3647236\",\n",
        "      \"w\": \"0.08401036\",\n",
        "      \"h\": \"0.07765585\"\n",
        "    }\n",
        "  }\n",
        "},\n",
        "{\n",
        "  \"type\": \"entity\",\n",
        "  \"entity\": {\n",
        "    \"tag\": {\n",
        "      \"value\": \"delivery truck\",\n",
        "      \"confidence\": \"0.92975134\"\n",
        "    },\n",
        "    \"box\": {\n",
        "      \"l\": \"0.5211431\",\n",
        "      \"t\": \"0.44633362\",\n",
        "      \"w\": \"0.16630614\",\n",
        "      \"h\": \"0.12689856\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "If all the code cells above have successfully finished running, return to the Readme page to continue.   "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}