{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Setting Up the Sample Specific Environment\n",
    "\n",
    "In this section, we will be creating environmental variables specific to this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../common')\n",
    "from env_variables import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Environmental Variables Specific to This Sample\n",
    "\n",
    "In the following sections, we will be creating a VM to act as our IoT Edge device. The following cell will set the type of VM that will be created. \n",
    "\n",
    "Verify that the VM type is available in your region. You may view this page for a full list of [VMs by region](https://azure.microsoft.com/en-us/global-infrastructure/services/?regions=non-regional,us-east,us-east-2,us-central,us-north-central,us-south-central,us-west-central,us-west,us-west-2&products=virtual-machines).\n",
    "\n",
    "For this sample, we will be using a Standard_DS3_v2 (CPU tier) VM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_type = \"Standard_DS3_v2\" #CPU tier VM\n",
    "tempVar = set_key(envPath, \"VM_TYPE\", vm_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will set a sample folder path absolute to the root folder of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvaSamplePath = \"utilities/video-analysis/notebooks/customvision\"\n",
    "tempVar = set_key(envPath, \"LVA_SAMPLE_PATH\", lvaSamplePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In later sections, we will be creating a Docker container image for our inference solution. The following cell will set the name of the Docker image to be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containerImageName = \"lvaextension:customvision\"\n",
    "tempVar = set_key(envPath, \"CONTAINER_IMAGE_NAME\", containerImageName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will set the folder to which debug files will be outputted in the IoT Edge device. The default location for debug files is `/tmp` folder in your IoT Edge device. If you want debug files to be sent elsewhere, you can change the value of the `debugOutputFolder` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugOutputFolder = \"/tmp\"\n",
    "tempVar = set_key(envPath, \"DEBUG_OUTPUT_FOLDER\", debugOutputFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will set the name of the media graph file to be used in this sample. We provide a variety of sample media graph files in the **live-video-analytics/MediaGraph** folder. To learn more about media graphs, [read our documentation here](https://docs.microsoft.com/en-us/azure/media-services/live-video-analytics-edge/media-graph-concept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topologyFile = \"motion-with-httpExtension/2.0/topology.json\"\n",
    "tempVar = set_key(envPath, \"TOPOLOGY_FILE\", topologyFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will extract the name of our sample media graph topology file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "\n",
    "with open(os.path.join(\"../../../../MediaGraph/topologies/\", topologyFile)) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "topologyName = data[\"name\"]\n",
    "tempVar = set_key(envPath, \"TOPOLOGY_NAME\", topologyName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will set the name of the media graph instance that will be used in later sections. With LVA, you may set more than one topology instance, so be sure to give each instance a unique name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphInstanceName = \"Sample-Graph-Instance\"\n",
    "tempVar = set_key(envPath, \"GRAPH_INSTANCE_NAME\", graphInstanceName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will set the media graph parameters specific to this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address of the RTSP camera stream source\n",
    "rtspUrl = \"rtsp://rtspsim:554/media/truck_video.mkv\"\n",
    "\n",
    "# Sensitivity of the motion detector low|medium|high\n",
    "motionSensitivity = \"medium\"\n",
    "\n",
    "# The address of the inference server\n",
    "httpAIServerAddress = \"http://lvaExtension/score\"\n",
    "\n",
    "# Name associated to the sink output\n",
    "hubSinkOutputName = \"inferences\"\n",
    "\n",
    "# Image file formats. Supported formats are jpeg, bmp and png\n",
    "imageEncoding = \"jpeg\"\n",
    "\n",
    "# preserveAspectRatio | pad\n",
    "imageScaleMode = \"pad\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will create parameters in JSon format to be used while deploying the media graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaGraphTopologyParameters = {\n",
    "          \"@apiVersion\": \"2.0\", \n",
    "          \"name\": graphInstanceName,\n",
    "          \"properties\": {\n",
    "            \"topologyName\": topologyName,\n",
    "            \"parameters\": [\n",
    "              {\n",
    "                \"name\": \"rtspUrl\",\n",
    "                \"value\": rtspUrl\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"motionSensitivity\",\n",
    "                \"value\": motionSensitivity\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"httpAIServerAddress\",\n",
    "                \"value\": httpAIServerAddress\n",
    "              },              \n",
    "              {\n",
    "                \"name\": \"hubSinkOutputName\",\n",
    "                \"value\": hubSinkOutputName\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"imageEncoding\",\n",
    "                \"value\": imageEncoding\n",
    "              },\n",
    "              {\n",
    "                \"name\": \"imageScaleMode\",\n",
    "                \"value\": imageScaleMode\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "\n",
    "with open(\"../common/.media_graph_topology_parameters.json\", \"w\") as f:\n",
    "    json.dump(mediaGraphTopologyParameters, f, indent=4)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}